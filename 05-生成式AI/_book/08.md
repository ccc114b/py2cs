## 第八章：推理模型與深度思考技術

本章將探討生成式人工智慧如何從單純的機率性語言生成，演進到具備複雜邏輯推理能力的深度思考模型。我們將從認知科學的理論基礎出發，進而建立其數學框架。

---

### 8.1 系統一與系統二思維 (System 1 & System 2 Thinking) 的 AI 實現

在認知心理學中，人類的決策過程通常被分為兩個系統：

* **系統一 (System 1)：** 直覺、快速且自動化的反應（例如：看見熟人立刻認出臉孔）。
* **系統二 (System 2)：** 慢速、邏輯性且需要消耗認知資源的思考（例如：計算 ）。

傳統的語言模型（Large Language Models, LLMs）在生成下一個字元時，主要模擬了系統一的快速反應。為了實現系統二，我們需要模型在輸出最終答案前，進行內部的推理與檢核。

---

### 8.2 思維鏈 (Chain-of-Thought, CoT) 的數學表達與自一致性

**思維鏈 (Chain-of-Thought, CoT)** 是一種引導模型產生中間推理步驟的技術。

#### 數學定義

假設給定一個問題 ，模型的目標是生成答案 。在標準的提示下，模型估計的是條件機率 。在 CoT 的框架下，我們引入一組中間推理步驟 ，則生成過程變為：


這表示最終答案的機率是所有可能推理路徑下產生該答案的機率總合。

#### 自一致性 (Self-consistency)

為了提高推理的準確性，我們可以對模型進行多次採樣。假設我們從  中獨立採樣出  個結果 ，則最終答案透過多數決（Majority Voting）決定：



其中  為指示函數 (Indicator Function)。

---

### 8.3 測試時計算量 (Test-time Computation) 的擴展定律 (Scaling Laws)

過去的擴展定律主要關注訓練時的計算量、參數深度與資料量。然而，推理模型顯示，增加**測試時計算量 (Test-time Computation)**（即讓模型花更多時間思考）也能顯著提升效能。

假設  為推論時投入的計算資源。實驗觀測到，對於困難的推理問題，模型效能  與計算量之間存在冪律（Power Law）關係：



其中  是特定任務的縮放指數。這意味著透過增加搜尋廣度或推理深度，較小的模型可能在特定任務上超越未經深度思考的大型模型。

---

### 8.4 搜索演算法：蒙地卡羅樹搜尋 (Monte Carlo Tree Search, MCTS) 在推理中的應用

為了在複雜的推理空間中找到最優路徑，AI 模型開始引入**蒙地卡羅樹搜尋 (Monte Carlo Tree Search, MCTS)**。

#### 數學定義

MCTS 將推理過程建模為一個狀態空間樹，其中每個節點  代表當前的推理狀態，邊  代表下一個推理步驟。搜尋過程主要維護兩個數值：

1. **訪問次數 **
2. **價值評估 **：代表在狀態  下採取行動  的預期獎勵。

在選擇路徑時，通常採用 **上限信心區間 (Upper Confidence Bound applied to Trees, UCT)** 公式來平衡探索與開發：



其中  是父節點的訪問次數， 是探索常數。

透過不斷地進行模擬與回傳 (Backpropagation)，模型能有效率地在龐大的邏輯空間中搜尋出正確的證明路徑或解題步驟。

