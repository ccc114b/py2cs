## 第四章：擴散模型原理

擴散模型（Diffusion Models）的靈感源自於物理學，特別是處理粒子隨機運動的非平衡態統計力學。其核心思想是將複雜的數據分佈逐漸轉化為簡單的高斯分佈，再學習如何將這個過程逆轉。

---

### 4.1 熱力學與非平衡態統計力學 (Nonequilibrium Statistical Mechanics)

在熱力學中，擴散是一個自發性的過程，物質會從高濃度區域向低濃度區域移動，最終達到熵（Entropy）最大的平衡態。從微觀角度看，這描述了粒子受隨機力影響的布朗運動（Brownian Motion）。

在生成式模型中，我們將數據（如圖像）視為分佈中的粒子。擴散過程就像是向一杯清水中滴入墨水，隨時間推移，墨水分子（數據特徵）會因隨機碰撞而擴散，直到整杯水變成均勻的灰色（純雜訊）。擴散模型學習的是如何「倒放電影」，從渾濁的水中將墨水分子重新聚集成原本的形狀。

---

### 4.2 前向擴散過程 (Forward Diffusion Process) 與馬可夫鏈

前向擴散過程是一個預先定義的過程，其目的是將原始數據  逐漸加入高斯雜訊（Gaussian Noise）。這個過程被建模為一個馬可夫鏈 (Markov Chain)，也就是說，第  步的狀態只取決於前一步 。

**數學定義：**
給定初始數據分佈 ，我們定義轉移概率為：



其中  是預先設定的變異數排程（Variance Schedule）。

利用重參數化技巧 (Reparameterization Trick)，我們可以推導出任意時刻  的狀態  與原始數據  的關係。令  且 ：



這意味著當  足夠大時，， 將近似於標準高斯分佈 。

---

### 4.3 逆向去噪過程 (Reverse Denoising Process)

如果前向過程是將數據毀滅成雜訊，逆向過程則是從雜訊中創造數據。我們希望學習一個轉移概率 ，使我們能從  回推到 。

**數學定義：**
由於真正的逆向條件分佈  是不可解的（Tractable），我們使用神經網路  來估計它。我們假設逆向過程也是高斯分佈：



訓練的目標是最小化變分下界 (Variational Lower Bound)，這最終會簡化為預測在前向過程中加入的雜訊 。損失函數通常表示為：



其中  就是我們要訓練的去噪模型。

---

### 4.4 分數函數匹配 (Score Matching) 與隨機微分方程

除了馬可夫鏈的視角，我們也可以從連續時間的角度來理解擴散模型，這涉及到了隨機微分方程 (Stochastic Differential Equations)。

**數學定義：**
前向擴散可以寫成如下的 SDE：



其中  是維納過程（Wiener Process）。對應的逆向過程同樣可以表示為一個逆向 SDE，這需要用到數據分佈的對數機率密度梯度，稱為分數函數 (Score Function)：



分數函數匹配的目標就是訓練一個模型  來逼近這個梯度。這與去噪自動編碼器的原理相通：分數函數指向的是數據密度增加最快的方向，也就是通往「純淨數據」的方向。

透過求解逆向 SDE，我們可以實現從純雜訊到高質量圖像的平滑轉換。
