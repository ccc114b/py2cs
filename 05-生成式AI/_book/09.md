## 第九章：多模態生成與跨領域應用

### 9.1 跨模態對齊 (Cross-modal Alignment) 的對比學習

在多模態學習中，核心挑戰在於如何將不同形式的資料（如文字與影像）映射到同一個共同向量空間 (Joint Vector Space) 中，使得語義相關的成對資料在空間中的距離越近越好。

**數學定義**

對比學習 (Contrastive Learning) 的目標是學習一個映射函數，將輸入資料轉換為特徵向量。假設我們有一組配對的資料集 ，其中  代表影像， 代表對應的文本。我們使用影像編碼器  與文本編碼器  分別得到向量  與 。

為了衡量兩者的相似度，我們通常使用餘弦相似度 (Cosine Similarity)：

對比學習常用的損失函數為資訊雜訊對比估計 (InfoNCE) 損失，其公式如下：

其中  是溫度參數 (Temperature Parameter)，用來控制相似度分佈的平滑程度。這個公式的直觀意義是：對於特定的影像 ，我們希望它與對應文本  的相似度 （正樣本）遠大於它與其他無關文本  的相似度 （負樣本）。

---

### 9.2 文本轉圖像 (Text-to-Image) 的潛在擴散模型

潛在擴散模型 (Latent Diffusion Models, LDM) 是目前主流的影像生成技術，其關鍵在於不直接在像素空間操作，而是在壓縮後的潛在空間 (Latent Space) 進行擴散過程。

**數學定義**

1. **感知壓縮 (Perceptual Compression)**：
利用一個預訓練的自動編碼器，將影像  編碼為低維度的潛在變數 ，並能透過解碼器還原 。
2. **擴散過程 (Diffusion Process)**：
在潛在空間中加入高斯雜訊 (Gaussian Noise)。定義一個時間步長 ，前向過程為：
，其中 。
3. **條件生成 (Conditional Generation)**：
為了達成文本控制，我們引入文本編碼 ，並使用神經網路  來預測雜訊：

在實作中， 通常採用 U-Net 架構，並透過交叉注意力機制 (Cross-Attention) 將文本向量  注入到影像生成的特徵圖中。

---

### 9.3 向量資料庫 (Vector Database) 與檢索增強生成 (Retrieval-Augmented Generation)

檢索增強生成 (Retrieval-Augmented Generation, RAG) 解決了大型語言模型 (LLM) 缺乏即時資訊或產生幻覺 (Hallucination) 的問題。

**數學定義**

給定一個使用者查詢  和一個大型文檔庫 。

1. **檢索 (Retrieval)**：
使用嵌入模型 (Embedding Model)  將查詢與文檔轉為向量。檢索函數  會從資料庫中找出相似度最高的  個文檔：


2. **生成 (Generation)**：
將檢索到的文檔作為上下文 (Context) 與原始查詢拼接，輸入給生成模型 ：



這可以看作是在給定檢索內容條件下的條件機率分佈 。

---

### 9.4 生成式 AI 的偏誤與安全性分析

模型在訓練過程中可能會吸收存在於網路數據中的偏誤 (Bias)，這反映在機率分佈的偏移上。

**數學定義**

假設存在一個敏感屬性 （如性別或種族），如果模型生成的內容  與  具有強相關性，則存在偏誤。我們可以使用統計平權 (Statistical Parity) 來衡量：

若上述等式不成立，則代表模型對不同群體存在預測上的差異。

此外，安全性分析常涉及對抗性攻擊 (Adversarial Attacks)。攻擊者試圖尋找一個微小的擾動 ，使得模型輸出錯誤結果：



其中  是限制擾動大小的範數，目的是在不改變人類感知的狀況下誤導模型。

