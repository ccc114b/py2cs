# 機率統計講義

* 講義：
    * 對話 -- https://gemini.google.com/app/2b798b515babe661
    * 分享 -- https://gemini.google.com/share/7e0059e97d2c

* 檢定：
    * 對話 -- https://gemini.google.com/app/223bb30301fa4b3c
    * 分享 -- https://gemini.google.com/share/9145617b5a88

* 習題：
    * 對話 -- https://gemini.google.com/app/73518308e2b93851
    * 分享 -- 不公開

* 進階主題：
    * [隨機微積分](05b-隨機微積分.md)
    * [馬可夫鏈與過程](05c-馬可夫鏈與過程.md)

## 前言

* https://www.threads.com/@ccckmit/post/DQLduUwkg-A

機率統計當中，最重要的定理，是中央極限定理

簡單來說，就是：

n 個樣本的平均值，會趨近常態分布

只要這 n 個樣本是互相獨立的，沒有前後相關性就可以。

## Q: 常見的機率模型有哪些？請分別列出離散和連續的機率模型

在機器學習和統計學中，機率模型扮演著至關重要的角色，它們幫助我們理解和預測隨機事件。機率模型可以根據其所處理的變數類型，主要分為**離散機率模型**和**連續機率模型**。

---

### 離散機率模型 (Discrete Probability Models)

離散機率模型適用於結果是可數的、有限或可列無限的事件，例如投擲骰子的點數、硬幣的正反面次數。

以下是一些常見的離散機率模型：

* **伯努利分佈 (Bernoulli Distribution)**
    * 這是一種最簡單的機率分佈，用來描述只有兩種可能結果的單次隨機試驗，例如成功或失敗、是或否。它只有一個參數 $p$，代表成功的機率。
    * **應用範例**：單次投擲硬幣，觀察結果是正面或反面。

* **二項式分佈 (Binomial Distribution)**
    * 二項式分佈描述在 $n$ 次獨立的伯努利試驗中，成功次數的機率分佈。它有兩個參數：試驗次數 $n$ 和單次試驗成功的機率 $p$。
    * **應用範例**：投擲一枚硬幣 10 次，觀察出現正面的次數。

* **泊松分佈 (Poisson Distribution)**
    * 泊松分佈描述在固定時間或空間區間內，某一事件發生的次數。它適用於事件發生機率很小，但試驗次數很大的情況。它只有一個參數 $\lambda$ (lambda)，代表單位時間或空間內事件發生的平均次數。
    * **應用範例**：某家醫院在一個小時內收治的急診病人數。

* **類別分佈 (Categorical Distribution)**
    * 這是伯努利分佈的推廣，用來描述單次隨機試驗有多種可能結果的情況，例如擲骰子的結果。它有多個參數 $p_1, p_2, ..., p_k$，代表每種結果發生的機率。
    * **應用範例**：單次投擲六面骰子，觀察出現點數 1 到 6 的機率。

---

### 連續機率模型 (Continuous Probability Models)

連續機率模型適用於結果是連續值的事件，例如人的身高、物體的重量、時間長度等。這些模型的機率密度函數 (Probability Density Function, PDF) 用來描述變數在某個區間內的機率。

以下是一些常見的連續機率模型：

* **常態分佈 (Normal Distribution)**，也稱為高斯分佈 (Gaussian Distribution)
    * 這是最重要、最廣泛使用的機率分佈。它的圖形呈現對稱的鐘形曲線，由兩個參數決定：平均數 $\mu$ (mu) 和標準差 $\sigma$ (sigma)。許多自然和社會現象都遵循近似常態分佈。
    * **應用範例**：一個群體的平均身高、考試成績的分佈。

* **均勻分佈 (Uniform Distribution)**
    * 在均勻分佈中，變數在特定區間 $[a, b]$ 內任何一點的機率密度都是相等的。
    * **應用範例**：一個轉盤停止在 0 到 360 度之間任何一個角度的機率。

* **指數分佈 (Exponential Distribution)**
    * 指數分佈描述**兩次事件發生之間的間隔時間**。它只有一個參數 $\lambda$，代表事件發生的平均速率。它具有「無記憶性」的特性，表示過去發生的事情不會影響未來的機率。
    * **應用範例**：兩個連續到達的顧客之間的時間間隔。

* **伽瑪分佈 (Gamma Distribution)**
    * 伽瑪分佈是指數分佈的推廣，可以描述在一段時間內發生 $k$ 次事件的等待時間。它有兩個參數：形狀參數 $k$ 和尺度參數 $\theta$。
    * **應用範例**：某個元件連續 $k$ 次失效的總等待時間。

這些機率模型是建立更複雜統計和機器學習模型的基礎，它們幫助我們從數據中提取有意義的洞見，並對未來做出預測。

## Q: 請用 python 示範上述機率模型的用法

好的，我們可以用 Python 來示範這些常見機率模型的用法。這裡我們將使用 **`scipy.stats`** 函式庫，它提供了豐富的機率分佈函數，可以方便地計算機率、生成隨機樣本以及繪製分佈圖。

為了讓展示更清晰，我們會針對每個模型進行以下操作：

1.  **設定參數**：定義模型的關鍵參數。
2.  **計算機率**：使用機率質量函數（PMF）或機率密度函數（PDF）來計算特定點或區間的機率。
3.  **生成樣本**：從該分佈中隨機抽取一些樣本。
4.  **繪製分佈圖**：視覺化地呈現該分佈的形狀。

-----

### 1\. 離散機率模型 (Discrete Probability Models)

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import bernoulli, binom, poisson, categorical

# 設定繪圖風格
plt.style.use('seaborn-v0_8-whitegrid')

# 伯努利分佈 (Bernoulli Distribution)
print("--- 伯努利分佈 ---")
p_bernoulli = 0.7  # 成功的機率
# 計算成功 (1) 和失敗 (0) 的機率
print(f"P(X=1): {bernoulli.pmf(1, p_bernoulli):.2f}")
print(f"P(X=0): {bernoulli.pmf(0, p_bernoulli):.2f}")
# 生成 10 個樣本
samples_bernoulli = bernoulli.rvs(p_bernoulli, size=10)
print(f"生成樣本: {samples_bernoulli}")
print("\n")


# 二項式分佈 (Binomial Distribution)
print("--- 二項式分佈 ---")
n_binom = 10  # 試驗次數
p_binom = 0.5  # 成功的機率
# 計算在 10 次試驗中，成功 5 次的機率
print(f"P(X=5): {binom.pmf(5, n_binom, p_binom):.2f}")
# 生成 20 個樣本
samples_binom = binom.rvs(n_binom, p_binom, size=20)
print(f"生成樣本 (20個): {samples_binom}")
# 繪製分佈圖
x_binom = np.arange(0, n_binom + 1)
pmf_binom = binom.pmf(x_binom, n_binom, p_binom)
plt.figure(figsize=(8, 4))
plt.bar(x_binom, pmf_binom, color='skyblue', edgecolor='black')
plt.title('二項式分佈 (n=10, p=0.5)')
plt.xlabel('成功次數')
plt.ylabel('機率')
plt.xticks(x_binom)
plt.show()
print("\n")


# 泊松分佈 (Poisson Distribution)
print("--- 泊松分佈 ---")
mu_poisson = 3  # 平均事件發生次數
# 計算事件發生 2 次的機率
print(f"P(X=2): {poisson.pmf(2, mu_poisson):.2f}")
# 生成 15 個樣本
samples_poisson = poisson.rvs(mu_poisson, size=15)
print(f"生成樣本 (15個): {samples_poisson}")
# 繪製分佈圖
x_poisson = np.arange(0, 10)
pmf_poisson = poisson.pmf(x_poisson, mu_poisson)
plt.figure(figsize=(8, 4))
plt.bar(x_poisson, pmf_poisson, color='lightgreen', edgecolor='black')
plt.title('泊松分佈 (平均值=3)')
plt.xlabel('事件發生次數')
plt.ylabel('機率')
plt.xticks(x_poisson)
plt.show()
print("\n")


# 類別分佈 (Categorical Distribution)
# scipy.stats 沒有直接的 categorical 函數，但可以通過 multinomial 實現
print("--- 類別分佈 ---")
# 假設擲一顆不均勻的六面骰子
p_categorical = [0.1, 0.1, 0.1, 0.2, 0.2, 0.3]
# 從中抽取 10 個樣本 (結果會是索引值)
# 注意：這裡使用 np.random.choice 更直觀
samples_categorical = np.random.choice(a=np.arange(1, 7), p=p_categorical, size=10)
print(f"擲骰子結果 (10次): {samples_categorical}")
print("\n")
```

-----

### 2\. 連續機率模型 (Continuous Probability Models)

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm, uniform, expon

# 設定繪圖風格
plt.style.use('seaborn-v0_8-whitegrid')

# 常態分佈 (Normal Distribution)
print("--- 常態分佈 ---")
mu_normal = 0  # 平均數
sigma_normal = 1  # 標準差
# 計算 x=1 時的機率密度
print(f"PDF at x=1: {norm.pdf(1, mu_normal, sigma_normal):.2f}")
# 計算 P(X <= 1.96) 的累積機率
print(f"CDF at x=1.96: {norm.cdf(1.96, mu_normal, sigma_normal):.2f}")
# 生成 1000 個樣本
samples_normal = norm.rvs(mu_normal, sigma_normal, size=1000)
# 繪製分佈圖
x_normal = np.linspace(-4, 4, 100)
pdf_normal = norm.pdf(x_normal, mu_normal, sigma_normal)
plt.figure(figsize=(8, 4))
plt.plot(x_normal, pdf_normal, color='blue', lw=2)
plt.title('標準常態分佈 (μ=0, σ=1)')
plt.xlabel('變數值')
plt.ylabel('機率密度')
plt.show()
print("\n")


# 均勻分佈 (Uniform Distribution)
print("--- 均勻分佈 ---")
a_uniform = 0  # 區間起點
b_uniform = 10  # 區間終點
# 計算 x=5 時的機率密度
print(f"PDF at x=5: {uniform.pdf(5, a_uniform, b_uniform):.2f}")
# 計算 P(X <= 5) 的累積機率
print(f"CDF at x=5: {uniform.cdf(5, a_uniform, b_uniform):.2f}")
# 生成 100 個樣本
samples_uniform = uniform.rvs(a_uniform, b_uniform - a_uniform, size=100)
# 繪製分佈圖
x_uniform = np.linspace(-2, 12, 100)
pdf_uniform = uniform.pdf(x_uniform, a_uniform, b_uniform - a_uniform)
plt.figure(figsize=(8, 4))
plt.plot(x_uniform, pdf_uniform, color='orange', lw=2)
plt.title('均勻分佈 (a=0, b=10)')
plt.xlabel('變數值')
plt.ylabel('機率密度')
plt.show()
print("\n")


# 指數分佈 (Exponential Distribution)
print("--- 指數分佈 ---")
lam_expon = 0.5  # 速率參數 (λ)
# 這裡 scipy 的 scale 參數為 1/λ
scale_expon = 1 / lam_expon
# 計算 x=2 時的機率密度
print(f"PDF at x=2: {expon.pdf(2, scale=scale_expon):.2f}")
# 計算 P(X <= 2) 的累積機率
print(f"CDF at x=2: {expon.cdf(2, scale=scale_expon):.2f}")
# 生成 500 個樣本
samples_expon = expon.rvs(scale=scale_expon, size=500)
# 繪製分佈圖
x_expon = np.linspace(0, 10, 100)
pdf_expon = expon.pdf(x_expon, scale=scale_expon)
plt.figure(figsize=(8, 4))
plt.plot(x_expon, pdf_expon, color='purple', lw=2)
plt.title('指數分佈 (λ=0.5)')
plt.xlabel('時間間隔')
plt.ylabel('機率密度')
plt.show()
print("\n")
```

## Q: 中央極限定理是什麼？

中央極限定理（Central Limit Theorem, CLT）是機率論和統計學中最重要、最基礎的定理之一。簡單來說，它揭示了一個驚人的現象：**當你從任何一個分佈中（不論其形狀如何，離散或連續）抽取足夠大的樣本，這些樣本的平均數所構成的分佈，會趨近於一個常態分佈（Normal Distribution）**。

這條定理之所以強大，在於它讓我們能對母體（population）進行推論，即使我們對母體的原始分佈一無所知。

### 中央極限定理的關鍵概念

1.  **抽樣分佈（Sampling Distribution of the Mean）**：
    想像你從一個大型的母體中，反覆抽取大小為 $n$ 的獨立隨機樣本。每次抽取後，你都計算這個樣本的平均數 $\bar{x}$。將所有這些平均數 $\bar{x}$ 繪製成一個分佈圖，這個圖就稱為**樣本平均數的抽樣分佈**。

2.  **趨近於常態分佈**：
    中央極限定理的核心就是，隨著樣本大小 $n$ 增加，這個樣本平均數的抽樣分佈會越來越像一個**常態分佈**。這個趨勢非常明顯，通常當 $n \ge 30$ 時，常態分佈的近似效果就已經相當不錯了。

3.  **分佈的參數**：
    這個由樣本平均數所形成的常態分佈，其平均數和標準差有著固定的關係：
    * **平均數**：其平均數等於母體的平均數 $\mu$。
    * **標準差**：其標準差稱為**標準誤（Standard Error）**，等於母體的標準差 $\sigma$ 除以樣本大小 $n$ 的平方根，即 $\frac{\sigma}{\sqrt{n}}$。

    這意味著，樣本平均數的分佈會以母體平均數為中心，而且隨著樣本數 $n$ 增加，其標準差會越來越小，分佈也變得越來越集中。

### 實際應用與重要性

中央極限定理是許多統計方法的基石，它的重要性體現在：

* **假說檢定（Hypothesis Testing）**：例如 $t$ 檢定和 $z$ 檢定，它們的有效性都依賴於樣本平均數分佈的常態近似。
* **信賴區間（Confidence Intervals）**：我們可以利用中央極限定理來估計一個母體參數（例如平均數）的信賴區間，即使我們不知道母體的原始分佈。
* **品質控制**：在製造業中，即使單一產品的缺陷分佈可能很奇怪，但批量產品的平均缺陷率會趨近於常態分佈，這使得我們可以利用常態分佈的特性來進行品質監控。

---

### 範例：投擲骰子

我們以一個簡單的範例來說明。擲一顆公平的六面骰子，其點數的原始分佈是**均勻分佈**（1 到 6 的機率都一樣，非常態）。

* **母體**：擲骰子的結果 $\{1, 2, 3, 4, 5, 6\}$
* **母體平均數** $\mu = (1+2+3+4+5+6)/6 = 3.5$

現在，我們進行重複實驗：每次連續擲 30 次骰子，並計算這 30 次擲出點數的平均值。我們重複這個實驗數千次。

中央極限定理告訴我們，這數千個平均數所組成的分佈，將會呈現出一個近似**鐘形**的常態分佈，其中心點將會落在 3.5 附近。這就是中央極限定理的魔力：不論原始分佈是什麼形狀，樣本平均數總會趨近於常態分佈。

## Q: 為何可以用常態分佈來進行檢定？什麼時候該用 z-test，什麼時候該用 t-test ?

您提的問題觸及了統計推論的核心。我們之所以可以用常態分佈來進行檢定，主要是因為**中央極限定理（Central Limit Theorem, CLT）**。

### 為何能用常態分佈進行檢定？

中央極限定理告訴我們，即使母體（population）本身不是常態分佈，但當我們從中抽取足夠大的樣本（通常 $n \ge 30$），這些**樣本平均數所構成的抽樣分佈**會近似於一個常態分佈。

這為統計檢定提供了理論基礎：
* **估計母體參數**：我們通常無法測量整個母體，只能依靠樣本來推斷母體的特徵。
* **計算機率**：既然樣本平均數的分佈是近似常態的，我們就可以利用常態分佈的特性（如標準差和常態分佈表）來計算一個特定的樣本平均數出現的機率。
* **做出推論**：如果我們觀察到的樣本結果，在常態分佈中是極不可能發生的（機率很小），我們就有理由推翻原來的假設（即虛無假設，$H_0$）。

換句話說，中央極限定理把一個我們不知道其分佈的複雜問題，轉化為一個我們能夠用常態分佈來解決的簡單問題。

---

### Z-test 與 T-test 的區別

這兩種檢定都是用來判斷**樣本平均數**與**母體平均數**之間是否有顯著差異。選擇使用哪一個，關鍵在於**母體標準差是否已知**。

#### 1. Z-test (Z 檢定)

**使用時機**：
* **母體標準差 ($\sigma$) 已知**。
* **樣本大小 ($n$) 夠大**（通常 $n \ge 30$）。

Z-test 的原理是將樣本平均數轉換為一個 **Z 分數**。這個 Z 分數代表了樣本平均數偏離母體平均數的標準差個數。

$$Z = \frac{\bar{x} - \mu}{\sigma / \sqrt{n}}$$

其中：
* $\bar{x}$ 是樣本平均數。
* $\mu$ 是母體平均數。
* $\sigma$ 是母體標準差。
* $n$ 是樣本大小。

如果這個 Z 分數的絕對值很大，代表我們的樣本平均數與假設的母體平均數相差甚遠，那麼我們就可以拒絕虛無假設。

**範例**：
假設某工廠生產的燈泡，其壽命的母體標準差 $\sigma$ 已知為 200 小時。現在我們從一批產品中隨機抽取 50 個燈泡，測得其平均壽命為 2500 小時。我們想檢定這批產品的平均壽命是否與工廠宣稱的 2400 小時有顯著差異。由於我們知道母體標準差且樣本大小大於 30，我們會使用 Z-test。

---

#### 2. T-test (t 檢定)

**使用時機**：
* **母體標準差 ($\sigma$) 未知**。
* **通常樣本大小較小**（$n < 30$），但即使樣本數大，只要母體標準差未知，t-test 仍然是更嚴謹的選擇。

在大多數實際情況中，我們通常不知道母體標準差，只能用**樣本標準差 ($s$)** 來估計。當我們使用樣本標準差時，會引入額外的不確定性，因此 Z 分佈不再適用，我們需要使用 **t 分佈**。

t 分佈的形狀與常態分佈相似，但尾部更「肥」，這反映了估計標準差所帶來的額外變異性。隨著樣本大小的增加，t 分佈會越來越趨近於常態分佈。

$$t = \frac{\bar{x} - \mu}{s / \sqrt{n}}$$

其中：
* $s$ 是樣本標準差。
* $t$ 檢定還需要考慮**自由度（degrees of freedom, $df = n-1$）**，這會影響 t 分佈的具體形狀。

**範例**：
假設一位老師想知道自己的班級學生平均成績是否與全校平均 80 分有顯著差異。他只隨機抽樣了 15 名學生，並計算出他們的平均分數與樣本標準差。由於樣本數小且母體標準差未知，他應該使用 t-test。

### 總結比較表

| 特徵 | Z-test (Z 檢定) | T-test (t 檢定) |
| :--- | :--- | :--- |
| **母體標準差** | **已知 ($\sigma$)** | **未知** (使用樣本標準差 $s$ 估計) |
| **樣本大小** | 通常大樣本 ($n \ge 30$) | 通常小樣本 ($n < 30$), 但大小樣本皆可 |
| **分佈** | 標準常態分佈 (Z 分佈) | t 分佈 (受自由度影響) |
| **公式** | $Z = \frac{\bar{x} - \mu}{\sigma / \sqrt{n}}$ | $t = \frac{\bar{x} - \mu}{s / \sqrt{n}}$ |

在實務中，由於母體標準差極少是已知的，**t-test 的應用比 Z-test 普遍得多**。只有在極少數情況下（例如全國性普查或已知母體變異的標準化檢定），才會用到 Z-test。

## Q: 請用 python 示範 z-test 如何用在單樣本檢定上

好的，我們將使用 Python 來示範如何進行單樣本 Z 檢定（One-Sample Z-Test）。

單樣本 Z 檢定的情境是：**當我們想知道一個樣本的平均值，是否與已知的母體平均值有顯著差異，而且我們也知道母體的標準差時。**

在 Python 中，`scipy.stats` 函式庫並沒有提供一個直接的 `ztest` 函式。但這沒關係，我們可以根據 Z 檢定的公式，自己動手實現這個過程，這也能幫助我們更深入地理解它的原理。

-----

### Z-test 實作步驟

1.  **設定虛無假設 ($H\_0$) 和對立假設 ($H\_a$)**：

      * $H\_0$ (虛無假設)：樣本平均值等於母體平均值。
      * $H\_a$ (對立假設)：樣本平均值不等於母體平均值（雙尾檢定），或大於/小於母體平均值（單尾檢定）。

2.  **計算 Z 統計量 (Z-statistic)**：
    使用 Z 檢定公式：$Z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}}$

3.  **計算 P 值 (P-value)**：
    P 值是觀察到目前樣本結果（或更極端結果）的機率。我們可以使用標準常態分佈（Standard Normal Distribution）的累積分佈函數（CDF）來計算。

4.  **做出決策**：
    將 P 值與預定的顯著水準 $\\alpha$（通常為 0.05）進行比較。

      * 如果 P 值 $\\le \\alpha$，則**拒絕**虛無假設，代表樣本平均值與母體平均值有顯著差異。
      * 如果 P 值 $\> \\alpha$，則**不拒絕**虛無假設，代表沒有足夠的證據證明兩者有顯著差異。

-----

### Python 程式碼示範

在這個範例中，我們假設某公司聲稱其生產的電池平均壽命為 50 小時，且母體標準差已知為 5 小時。我們隨機抽取 40 顆電池，測得其平均壽命為 48.5 小時。我們想檢定這批電池的壽命是否與公司聲稱的有顯著差異。

```python
import numpy as np
from scipy.stats import norm

# --- 1. 設定假設與參數 ---

# 虛無假設 H0: 母體平均壽命 (μ) = 50 小時
mu_0 = 50

# 樣本數據
sample_mean = 48.5  # 樣本平均數 (x̄)
n = 40              # 樣本大小 (n)

# 母體參數
sigma = 5           # 母體標準差 (σ)
alpha = 0.05        # 顯著水準 (α)

# --- 2. 計算 Z 統計量 ---

# 計算標準誤 (standard error)
standard_error = sigma / np.sqrt(n)
print(f"母體標準差 (σ): {sigma}")
print(f"樣本大小 (n): {n}")
print(f"標準誤 (Standard Error): {standard_error:.4f}")
print("-" * 30)

# 計算 Z 統計量
z_statistic = (sample_mean - mu_0) / standard_error
print(f"樣本平均壽命 (x̄): {sample_mean}")
print(f"假設母體平均壽命 (μ): {mu_0}")
print(f"Z 統計量 (Z-statistic): {z_statistic:.4f}")
print("-" * 30)


# --- 3. 計算 P 值 (雙尾檢定) ---

# 計算單尾 P 值：P(Z < -1.897)
# 我們使用 norm.cdf() 來計算累積機率
p_value_one_tailed = norm.cdf(z_statistic)

# 因為是雙尾檢定（判斷「不等於」），所以要將單尾 P 值乘以 2
p_value_two_tailed = p_value_one_tailed * 2
print(f"單尾 P 值 (one-tailed P-value): {p_value_one_tailed:.4f}")
print(f"雙尾 P 值 (two-tailed P-value): {p_value_two_tailed:.4f}")
print("-" * 30)


# --- 4. 做出決策 ---

print(f"顯著水準 (α): {alpha}")
if p_value_two_tailed <= alpha:
    print("結論: 由於 P 值 ≤ α，我們拒絕虛無假設。")
    print("有足夠證據證明這批電池的平均壽命與 50 小時有顯著差異。")
else:
    print("結論: 由於 P 值 > α，我們不拒絕虛無假設。")
    print("沒有足夠證據證明這批電池的平均壽命與 50 小時有顯著差異。")

```

### 程式碼說明：

  * **`mu_0`**：這是虛無假設中我們假設的母體平均值，即 50 小時。
  * **`standard_error`**：這是樣本平均數抽樣分佈的標準差，公式為 $\\sigma / \\sqrt{n}$。
  * **`z_statistic`**：這是我們算出的 Z 值。`z_statistic` 為 -1.897，代表我們的樣本平均值比母體平均值低了約 1.9 個標準誤。
  * **`norm.cdf(z_statistic)`**：這是 `scipy.stats.norm` 函式庫的累積分佈函數（CDF），它能計算出**從負無限大到 `z_statistic` 的累積機率**。
  * **`p_value_two_tailed`**：因為我們的對立假設是「不等於」，所以是雙尾檢定。Z 分佈是對稱的，因此我們將單尾 P 值乘以 2，得到兩邊極端情況下的總機率。

這個範例清楚地展示了 Z 檢定的完整流程，從設定假設、計算統計量，到最終基於 P 值做出結論。

## Q: 請用 python 示範如何用 t-test 進行雙樣本檢定

好的，我們來示範如何用 Python 進行**雙樣本 t 檢定 (Two-Sample t-test)**。

雙樣本 t 檢定用來比較**兩個獨立樣本的平均數**，以判斷它們是否來自平均數相等的母體。這個檢定是 t 檢定中最常見的一種，應用場景非常廣泛，例如：

  * 比較兩種不同藥物的療效。
  * 分析兩個不同班級的考試成績是否有顯著差異。
  * 檢定男女薪資是否存在顯著差異。

-----

### 雙樣本 t 檢定的類型

雙樣本 t 檢定主要分為兩種，選擇哪一種取決於**兩個樣本的母體變異數是否相等**：

1.  **獨立樣本 t 檢定（Independent Two-Sample t-test）**：這是最常見的類型，用於比較兩個不相關的組別。
2.  **配對樣本 t 檢定（Paired Two-Sample t-test）**：用於比較同一組別在不同時間點的數據，例如藥物治療前後的數據。

我們將示範最常見的**獨立雙樣本 t 檢定**。這個檢定還有一個重要的前提：**我們不知道兩個母體的標準差，只能用樣本標準差來估計**。

-----

### Python 程式碼示範

在這個範例中，我們假設某公司正在評估兩種不同的廣告策略（A 和 B），並想知道哪一種能帶來更高的銷售額。我們從分別使用這兩種策略的區域隨機抽取了兩組數據，現在要檢定這兩種廣告策略帶來的平均銷售額是否有顯著差異。

我們將使用 `scipy.stats` 函式庫中的 `ttest_ind()` 函數，它能方便地完成獨立雙樣本 t 檢定。

```python
import numpy as np
from scipy import stats

# 假設兩組廣告策略帶來的銷售額數據
# 廣告 A 的數據
ad_A_sales = np.array([120, 150, 130, 160, 145, 135, 155, 125, 140, 165, 150, 130, 125, 140, 155])

# 廣告 B 的數據
ad_B_sales = np.array([110, 125, 105, 135, 115, 120, 130, 100, 115, 125, 110, 105, 120, 115, 130])

# --- 1. 設定假設 ---
# 虛無假設 (H0): 兩組的平均銷售額相等 (μA = μB)
# 對立假設 (Ha): 兩組的平均銷售額不相等 (μA ≠ μB)

# --- 2. 進行 t 檢定 ---
# ttest_ind() 函數會自動計算 t 統計量和 P 值
# equal_var=True 假設兩組母體變異數相等 (這是默認值)
# equal_var=False 則不假設變異數相等 (稱為 Welch's t-test)
# 我們這裡假設變異數不一定相等，因此設定 equal_var=False
t_statistic, p_value = stats.ttest_ind(ad_A_sales, ad_B_sales, equal_var=False)

# --- 3. 輸出結果 ---
print(f"廣告 A 的樣本平均數: {ad_A_sales.mean():.2f}")
print(f"廣告 B 的樣本平均數: {ad_B_sales.mean():.2f}")
print("-" * 40)
print(f"t 統計量 (t-statistic): {t_statistic:.4f}")
print(f"P 值 (P-value): {p_value:.4f}")
print("-" * 40)

# --- 4. 做出決策 ---
alpha = 0.05  # 設定顯著水準
print(f"顯著水準 (α): {alpha}")

if p_value < alpha:
    print("結論：由於 P 值 < α，我們拒絕虛無假設。")
    print("有足夠證據證明兩種廣告策略的平均銷售額有顯著差異。")
else:
    print("結論：由於 P 值 ≥ α，我們不拒絕虛無假設。")
    print("沒有足夠證據證明兩種廣告策略的平均銷售額有顯著差異。")

```

### 程式碼說明：

  * **`stats.ttest_ind()`**：這是核心函數，用於獨立雙樣本 t 檢定。它接收兩個數據陣列作為輸入，並返回**t 統計量**和**雙尾 P 值**。
  * **`equal_var=False`**：這個參數很重要，它決定了檢定時是否假設兩個母體的變異數相等。
      * 當**不確定**母體變異數是否相等時，將 `equal_var` 設為 `False` 是更穩健的選擇，這時進行的是**韋爾奇氏 t 檢定 (Welch's t-test)**。
      * 如果你有理由相信兩個母體變異數是相等的，可以設為 `True`。

### 結果解釋：

  * **t 統計量**：這是衡量兩個樣本平均數差異的指標，其絕對值越大，代表兩者的差異越大。
  * **P 值**：這是最重要的輸出。它代表在虛無假設為真的前提下（即兩種廣告策略沒有差異），觀測到目前樣本結果（或更極端結果）的機率。
  * **最終結論**：
      * 若 **P 值小於 0.05**，表示這個差異不太可能是隨機造成的，因此我們有信心拒絕「沒有差異」的虛無假設。
      * 若 **P 值大於 0.05**，表示這個差異可能是隨機誤差造成的，我們無法斷定兩種廣告策略有顯著差異。

這個範例完美地展示了如何用幾行 Python 程式碼，就完成一個完整的雙樣本 t 檢定，並根據結果做出有意義的統計推論。

## Q: 如果母體標準差未知，那如何進行單樣本平均值檢定？

如果母體標準差未知，你需要使用**單樣本 t 檢定 (One-Sample t-test)** 來檢定樣本平均值是否與假設的母體平均值有顯著差異。

這是因為在絕大多數實際情況中，我們無法得知母體的標準差 $\\sigma$。當我們必須用**樣本標準差 $s$** 來估計母體標準差時，會引入額外的不確定性。這時，Z 分佈就不再適用，我們需要改用**t 分佈**來進行檢定。

t 檢定比 Z 檢定更為常見，因為它更能反映真實世界中母體參數未知的狀況。

-----

### 單樣本 t 檢定的原理

單樣本 t 檢定的邏輯與 Z 檢定非常相似，只是將公式中的母體標準差 $\\sigma$ 替換為樣本標準差 $s$，並使用 t 分佈來計算機率。

**t 統計量公式：**

$$t = \frac{\bar{x} - \mu}{s / \sqrt{n}}$$

其中：

  * $\\bar{x}$ 是**樣本平均值**。
  * $\\mu$ 是**假設的母體平均值**（來自虛無假設 $H\_0$）。
  * $s$ 是**樣本標準差**。
  * $n$ 是**樣本大小**。

這個 t 統計量服從**自由度 (degrees of freedom, $df = n-1$)** 的 t 分佈。自由度會影響 t 分佈的形狀：樣本數 $n$ 越小，自由度越小，t 分佈的尾部會越「肥」，代表不確定性越高；當 $n$ 夠大時，t 分佈會非常接近常態分佈。

### Python 程式碼示範

我們沿用 Z 檢定的例子：假設某公司聲稱其生產的電池平均壽命為 50 小時。這次，我們**不知道母體的標準差**，只從隨機抽取的 40 顆電池中，測得其平均壽命為 48.5 小時，**樣本標準差為 4.5 小時**。現在我們要用 t 檢定來判斷這批電池的壽命是否與公司聲稱的有顯著差異。

我們可以使用 `scipy.stats` 函式庫中的 `ttest_1samp()` 函數，它能方便地完成單樣本 t 檢定。

```python
import numpy as np
from scipy import stats

# 假設的母體平均數 (來自虛無假設)
mu_0 = 50

# 樣本數據
sample_data = np.array([48.5, 49.2, 51.0, 47.8, 50.1, 46.5, 49.8, 52.3, 47.0, 48.9,
                        49.5, 48.0, 50.5, 47.5, 51.5, 48.8, 49.3, 50.8, 47.2, 49.9,
                        51.1, 48.2, 50.2, 46.8, 49.6, 50.6, 47.7, 48.7, 51.2, 49.7,
                        48.1, 49.4, 50.3, 46.7, 50.9, 47.3, 48.6, 51.3, 47.9, 49.1])

# --- 1. 計算樣本統計量 ---
sample_mean = np.mean(sample_data)
sample_std = np.std(sample_data, ddof=1)  # ddof=1 計算樣本標準差
n = len(sample_data)

print(f"樣本平均值 (x̄): {sample_mean:.2f}")
print(f"樣本標準差 (s): {sample_std:.2f}")
print(f"樣本大小 (n): {n}")
print("-" * 30)

# --- 2. 進行 t 檢定 ---
# ttest_1samp 函數會自動計算 t 統計量和 P 值
t_statistic, p_value = stats.ttest_1samp(sample_data, popmean=mu_0)

# --- 3. 輸出結果 ---
print(f"t 統計量 (t-statistic): {t_statistic:.4f}")
print(f"P 值 (P-value): {p_value:.4f}")
print("-" * 30)

# --- 4. 做出決策 ---
alpha = 0.05
print(f"顯著水準 (α): {alpha}")

if p_value < alpha:
    print("結論：由於 P 值 < α，我們拒絕虛無假設。")
    print("有足夠證據證明這批電池的平均壽命與 50 小時有顯著差異。")
else:
    print("結論：由於 P 值 ≥ α，我們不拒絕虛無假設。")
    print("沒有足夠證據證明這批電池的平均壽命與 50 小時有顯著差異。")
```

### 程式碼說明：

  * **`np.std(..., ddof=1)`**：這裡的 `ddof=1` (Delta Degrees of Freedom) 參數非常重要，它告訴 NumPy 使用 $n-1$ 作為分母來計算**樣本標準差**，而不是用 $n$ 來計算母體標準差。這符合統計學中對樣本標準差的定義。
  * **`stats.ttest_1samp()`**：這是核心函數，它接收樣本數據陣列和假設的母體平均數 `popmean` 作為輸入，並返回**t 統計量**和**雙尾 P 值**。

這個例子清楚地展示了當母體標準差未知時，如何正確地使用單樣本 t 檢定來進行統計推論。在大多數情況下，這會是你進行單樣本平均值檢定的首選方法。

